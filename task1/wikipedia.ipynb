{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NER with sentence picker: demonstrated with wikipedia page** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in txt with wikipedia page for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "url = \"https://raw.githubusercontent.com/laurenzbrahner/BigDataScenarios/main/data/NER_text_Wikipedia_crawl.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Delete the brackets\n",
    "pattern = r'\\[.*?\\]'\n",
    "text = re.sub(pattern, '', text)\n",
    "\n",
    "# split all sentences in a list\n",
    "sentences_list = text.split(\". \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main input processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_wikipedia(sentence, entities_to_display):\n",
    "  # use transformer model\n",
    "  data = ner(sentence)\n",
    "  # to dataframe\n",
    "  data = pd.DataFrame(data)\n",
    "  # Filter entities if user selected one\n",
    "  if entities_to_display:\n",
    "    data = data[data['entity_group'].isin(entities_to_display)]\n",
    "\n",
    "  word_list = data['word'].tolist()\n",
    "  entity_list = data['entity_group'].tolist()\n",
    "\n",
    "  word_entity_df = pd.DataFrame({'Word': word_list, 'Entity': entity_list})\n",
    "  word_freq = word_entity_df.groupby(['Word', 'Entity']).size().reset_index(name='Frequency')\n",
    "    \n",
    "  # Colors for the Points in the Scatter Plot\n",
    "  color_scale = alt.Scale(domain=['ORG', 'LOC', 'MISC', 'PER'], range=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "\n",
    "   # Define Scatter plot\n",
    "  scatter = alt.Chart(word_freq).mark_circle(opacity=0.7, stroke='black', strokeWidth=0.5).encode(\n",
    "        x=alt.X('Frequency', scale=alt.Scale(padding=1), axis=alt.Axis(tickCount=5)),\n",
    "        y=alt.Y('Word', sort='-x'),\n",
    "        size=alt.Size('Frequency', scale=alt.Scale(range=[200, 1500]), title='Frequency'),\n",
    "        color=alt.Color('Entity', scale=color_scale, legend=alt.Legend(title='Entity')),\n",
    "        tooltip=['Word', 'Frequency', 'Entity']\n",
    "    ).properties(\n",
    "        title='Words and Entities',\n",
    "        width=500,\n",
    "        height=600\n",
    "    ).configure_view(\n",
    "        strokeWidth=0,\n",
    "        fill='f5f5f5'\n",
    "    ).configure_title(\n",
    "        fontSize=25,\n",
    "        anchor='start'\n",
    "    ).configure_axis(\n",
    "        labelColor='grey',\n",
    "        labelFontSize=12,\n",
    "        titleFontSize=15\n",
    "    ).configure_legend(\n",
    "        labelFontSize=12,\n",
    "        symbolSize=150,\n",
    "        symbolStrokeWidth=2,\n",
    "        labelPadding=10,\n",
    "        padding=40\n",
    "    ).configure_axisX(\n",
    "        grid=False\n",
    "    )\n",
    "  # Save the plot as html\n",
    "  scatter.save('scatter_plot.html')  \n",
    "\n",
    "  # Sort the dataframe by frequency\n",
    "  sorted_word_freq = word_freq.sort_values(by='Frequency', ascending=False)\n",
    "  # Return the dataframe, the scatter plot and the html file\n",
    "  return sorted_word_freq, scatter, \"scatter_plot.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Definition of the Gradio UI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkbox and dropdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CheckboxGroup\n",
    "checkbox = gr.CheckboxGroup([\"LOC\", \"MISC\", \"PER\", \"ORG\"], \n",
    "                            label=\"Choose the entities you want to see\",\n",
    "                            info=\"If you select nothing, every entity will be selected\")\n",
    "\n",
    "# Define the Dropdown\n",
    "dropdown = gr.Dropdown(sentences_list, label='Choose an article you would like to have summarized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate and launch the Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=ner_wikipedia,\n",
    "    inputs=[dropdown, checkbox],\n",
    "    outputs=[\"dataframe\",\"plot\", \"file\"],\n",
    "    title=\"Named Entity Recognition\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The entire code in one piece:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import altair as  alt\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# URL\n",
    "url = \"https://raw.githubusercontent.com/laurenzbrahner/BigDataScenarios/main/data/NER_text_Wikipedia_crawl.txt\"\n",
    "\n",
    "# Load the text\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Delete the brackets\n",
    "pattern = r'\\[.*?\\]'\n",
    "text = re.sub(pattern, '', text)\n",
    "\n",
    "# split all sentences in a list\n",
    "sentences_list = text.split(\". \")\n",
    "\n",
    "\n",
    "def ner_wikipedia(sentence, entities_to_display):\n",
    "  # use transformer model\n",
    "  data = ner(sentence)\n",
    "  # to dataframe\n",
    "  data = pd.DataFrame(data)\n",
    "  # Filter entities if user selected one\n",
    "  if entities_to_display:\n",
    "    data = data[data['entity_group'].isin(entities_to_display)]\n",
    "\n",
    "  word_list = data['word'].tolist()\n",
    "  entity_list = data['entity_group'].tolist()\n",
    "\n",
    "  word_entity_df = pd.DataFrame({'Word': word_list, 'Entity': entity_list})\n",
    "  word_freq = word_entity_df.groupby(['Word', 'Entity']).size().reset_index(name='Frequency')\n",
    "    \n",
    "  # Colors for the Points in the Scatter Plot\n",
    "  color_scale = alt.Scale(domain=['ORG', 'LOC', 'MISC', 'PER'], range=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "\n",
    "   # Define Scatter plot\n",
    "  scatter = alt.Chart(word_freq).mark_circle(opacity=0.7, stroke='black', strokeWidth=0.5).encode(\n",
    "        x=alt.X('Frequency', scale=alt.Scale(padding=1), axis=alt.Axis(tickCount=5)),\n",
    "        y=alt.Y('Word', sort='-x'),\n",
    "        size=alt.Size('Frequency', scale=alt.Scale(range=[200, 1500]), title='Frequency'),\n",
    "        color=alt.Color('Entity', scale=color_scale, legend=alt.Legend(title='Entity')),\n",
    "        tooltip=['Word', 'Frequency', 'Entity']\n",
    "    ).properties(\n",
    "        title='Words and Entities',\n",
    "        width=500,\n",
    "        height=600\n",
    "    ).configure_view(\n",
    "        strokeWidth=0,\n",
    "        fill='f5f5f5'\n",
    "    ).configure_title(\n",
    "        fontSize=25,\n",
    "        anchor='start'\n",
    "    ).configure_axis(\n",
    "        labelColor='grey',\n",
    "        labelFontSize=12,\n",
    "        titleFontSize=15\n",
    "    ).configure_legend(\n",
    "        labelFontSize=12,\n",
    "        symbolSize=150,\n",
    "        symbolStrokeWidth=2,\n",
    "        labelPadding=10,\n",
    "        padding=40\n",
    "    ).configure_axisX(\n",
    "        grid=False\n",
    "    )\n",
    "\n",
    "  scatter.save('scatter_plot.html')  \n",
    "\n",
    "  sorted_word_freq = word_freq.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "  return sorted_word_freq, scatter, \"scatter_plot.html\"\n",
    "\n",
    "\n",
    "\n",
    "checkbox = gr.CheckboxGroup([\"LOC\", \"MISC\", \"PER\", \"ORG\"], \n",
    "                            label=\"Choose the entities you want to see\",\n",
    "                            info=\"If you select nothing, every entity will be selected\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dropdown = gr.Dropdown(sentences_list, label='Choose an article you would like to have summarized')\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=ner_wikipedia,\n",
    "    inputs=[dropdown, checkbox],\n",
    "    outputs=[\"dataframe\",\"plot\", \"file\"],\n",
    "    title=\"Named Entity Recognition\"\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
